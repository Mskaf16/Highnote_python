{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highnote       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/michelleskaf/Documents/MSBA2022/DataMining/HN_data_PostModule.csv')\n",
    "data = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:24].values\n",
    "y = data.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(X)\n",
    "X=imputer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset to 75/25 train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling the data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function for a model \n",
    "def models(X_train, y_train):\n",
    "        \n",
    "        #KNN\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        knn = KNeighborsClassifier()\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        #Logistic Regression\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        log = LogisticRegression(random_state=0)\n",
    "        log.fit(X_train, y_train)\n",
    "        \n",
    "        #Decision Tree\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        tree = DecisionTreeClassifier(random_state=0, criterion='entropy')\n",
    "        tree.fit(X_train, y_train)\n",
    "        \n",
    "        #Random Forest \n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        forest = RandomForestClassifier(n_estimators=10, criterion='entropy',random_state=0)\n",
    "        forest.fit(X_train, y_train)\n",
    "        \n",
    "        #XGBoost\n",
    "        #from xgb\n",
    "        \n",
    "        #Print accuracy on train data \n",
    "        print('[0]KNN Accuracy:', knn.score(X_train, y_train))\n",
    "        print('[1]Logistic Regression Accuracy:', log.score(X_train, y_train))\n",
    "        print('[2]Decision Tree Accuracy:', tree.score(X_train, y_train))\n",
    "        print('[3]Random Forest Accuracy:', forest.score(X_train, y_train))\n",
    "        \n",
    "        return knn, log, tree, forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]KNN Accuracy: 0.937656232511286\n",
      "[1]Logistic Regression Accuracy: 0.9319603526968374\n",
      "[2]Decision Tree Accuracy: 1.0\n",
      "[3]Random Forest Accuracy: 0.9884963126018231\n"
     ]
    }
   ],
   "source": [
    "#accuracy on the training data\n",
    "model = models(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "[[24783   189]\n",
      " [ 1749    83]]\n",
      "('Testing Accuracy:', 0.9276973586031936)\n",
      "\n",
      "Model 1\n",
      "[[24822   150]\n",
      " [ 1754    78]]\n",
      "('Testing Accuracy:', 0.92896582599612)\n",
      "\n",
      "Model 2\n",
      "[[20939  4033]\n",
      " [ 1416   416]]\n",
      "('Testing Accuracy:', 0.7967094463512908)\n",
      "\n",
      "Model 3\n",
      "[[24809   163]\n",
      " [ 1738    94]]\n",
      "('Testing Accuracy:', 0.9290777495896135)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test model accuracy on test data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for i in range(len(model)):\n",
    "    print('Model', i)\n",
    "    cm = confusion_matrix(y_test,model[i].predict(X_test))\n",
    "\n",
    "    TP = cm[0][0]\n",
    "    TN = cm[1][1]\n",
    "    FP = cm[1][0]\n",
    "    FN = cm[0][1]\n",
    "\n",
    "    print(cm)\n",
    "    print(('Testing Accuracy:', (TP + TN)/(TP + TN + FP + FN)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     24972\n",
      "           1       0.31      0.05      0.08      1832\n",
      "\n",
      "    accuracy                           0.93     26804\n",
      "   macro avg       0.62      0.52      0.52     26804\n",
      "weighted avg       0.89      0.93      0.90     26804\n",
      "\n",
      "0.9276973586031936\n",
      "\n",
      "Model 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     24972\n",
      "           1       0.34      0.04      0.08      1832\n",
      "\n",
      "    accuracy                           0.93     26804\n",
      "   macro avg       0.64      0.52      0.52     26804\n",
      "weighted avg       0.89      0.93      0.90     26804\n",
      "\n",
      "0.92896582599612\n",
      "\n",
      "Model 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.88     24972\n",
      "           1       0.09      0.23      0.13      1832\n",
      "\n",
      "    accuracy                           0.80     26804\n",
      "   macro avg       0.52      0.53      0.51     26804\n",
      "weighted avg       0.88      0.80      0.83     26804\n",
      "\n",
      "0.7967094463512908\n",
      "\n",
      "Model 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     24972\n",
      "           1       0.37      0.05      0.09      1832\n",
      "\n",
      "    accuracy                           0.93     26804\n",
      "   macro avg       0.65      0.52      0.53     26804\n",
      "weighted avg       0.90      0.93      0.90     26804\n",
      "\n",
      "0.9290777495896135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "for i in range(len(model)):\n",
    "    print('Model', i)\n",
    "    print(classification_report(y_test, model[i].predict(X_test)))\n",
    "    print(accuracy_score(y_test, model[i].predict(X_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
